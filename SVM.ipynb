{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.resp_h</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>orig_bytes</th>\n",
       "      <th>resp_bytes</th>\n",
       "      <th>conn_state</th>\n",
       "      <th>missed_bytes</th>\n",
       "      <th>history</th>\n",
       "      <th>orig_pkts</th>\n",
       "      <th>orig_ip_bytes</th>\n",
       "      <th>resp_pkts</th>\n",
       "      <th>resp_ip_bytes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031471</td>\n",
       "      <td>-0.120580</td>\n",
       "      <td>-0.091638</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031437</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>-0.032746</td>\n",
       "      <td>-0.035204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031469</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>0.114779</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.025729</td>\n",
       "      <td>-0.022584</td>\n",
       "      <td>-0.021844</td>\n",
       "      <td>-0.016371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025755</td>\n",
       "      <td>0.056852</td>\n",
       "      <td>-0.089369</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025729</td>\n",
       "      <td>-0.024210</td>\n",
       "      <td>-0.032746</td>\n",
       "      <td>-0.035204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.031469</td>\n",
       "      <td>0.083804</td>\n",
       "      <td>0.114779</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.025729</td>\n",
       "      <td>-0.022584</td>\n",
       "      <td>-0.021844</td>\n",
       "      <td>-0.016371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.025717</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.232731</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.028072</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.020022</td>\n",
       "      <td>-0.015129</td>\n",
       "      <td>-0.021844</td>\n",
       "      <td>-0.009663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id.resp_h  proto  service  duration  orig_bytes  resp_bytes  conn_state  \\\n",
       "0          8      2        1 -0.031471   -0.120580   -0.091638           2   \n",
       "1          8      2        1 -0.031469    0.083804    0.114779           5   \n",
       "2          8      2        1 -0.025755    0.056852   -0.089369           2   \n",
       "3          8      2        1 -0.031469    0.083804    0.114779           5   \n",
       "4          8      2        1 -0.025717    0.144445    0.232731           5   \n",
       "\n",
       "   missed_bytes  history  orig_pkts  orig_ip_bytes  resp_pkts  resp_ip_bytes  \\\n",
       "0     -0.028072        1  -0.031437      -0.033291  -0.032746      -0.035204   \n",
       "1     -0.028072        2  -0.025729      -0.022584  -0.021844      -0.016371   \n",
       "2     -0.028072        1  -0.025729      -0.024210  -0.032746      -0.035204   \n",
       "3     -0.028072        2  -0.025729      -0.022584  -0.021844      -0.016371   \n",
       "4     -0.028072        2  -0.020022      -0.015129  -0.021844      -0.009663   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/preprocessed_CTU-IoT-Malware-Capture-21-1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What's a hyperplane?\n",
    "\n",
    "A hyperplane is a subspace of one dimension less than its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines. In general, a hyperplane of an n-dimensional space is an (n-1)-dimensional subspace. So, in the xy plane, a hyperplane is a line. In the xyz space, a hyperplane is a plane. In the xyzw space, a hyperplane is a 3-dimensional space. And so on.\n",
    "\n",
    "<img src=\"https://images.deepai.org/glossary-terms/3bb86574825445cba73a67222b744648/hyperplane.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithm tries to find a hyperplane that separates the data into two classes, as seen in the picture above. The hyperplane is chosen so that the distance from it to the nearest data point on each side (the margin) is maximized. The data points that are closest to the hyperplane are called support vectors.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/332248436/figure/fig5/AS:864758303563793@1583185854982/Support-Vector-Machine-visualization.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing hyperparameters\n",
    "- Kernel: linear, polynomial, radial basis function (RBF), sigmoid. \n",
    "- Gamma: Kernel coefficient for RBF, polynomial, sigmoid.\n",
    "- C: Penalty parameter C of the error term.\n",
    "    - C controls the trade-off between maximizing the margin and minimizing the classification error. A smaller C makes the decision boundary more robust to misclassified data points, while a larger C allows the model to classify more training points correctly.\n",
    "    - A higher C may lead to overfitting, while a lower C may lead to underfitting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = svm.SVC(kernel='linear', C=1, gamma=1)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "\n",
    "svm_rbf = svm.SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "svm_sig = svm.SVC(kernel='sigmoid', C=1, gamma=1)\n",
    "svm_sig.fit(X_train, y_train)\n",
    "y_pred_sig = svm_sig.predict(X_test)\n",
    "\n",
    "svm_poly = svm.SVC(kernel='poly', C=1, gamma=1)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "y_pred_poly = svm_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 score:  0.9985882167180219\n",
      "RBF SVM F1 score:  1.0\n",
      "Sigmoid SVM F1 score:  0.9931663028355677\n",
      "Polynomial SVM F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Compare the accuracy of the models with F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Linear SVM F1 score: \", f1_score(y_test, y_pred_linear, average='weighted'))\n",
    "print(\"RBF SVM F1 score: \", f1_score(y_test, y_pred_rbf, average='weighted'))\n",
    "print(\"Sigmoid SVM F1 score: \", f1_score(y_test, y_pred_sig, average='weighted'))\n",
    "print(\"Polynomial SVM F1 score: \", f1_score(y_test, y_pred_poly, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, most models perform almost perfectly, taking into account that we are using a rather small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "df_big = pd.read_csv(\"/home/pedranji/Projects/iot/data/preprocessed_CTU-IoT-Malware-Capture-48-1.csv\")\n",
    "\n",
    "X = df_big.drop(['label'], axis=1)\n",
    "y = df_big['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_big[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384437    1\n",
       "3233363    1\n",
       "1941322    1\n",
       "1618321    1\n",
       "3162842    1\n",
       "          ..\n",
       "1692743    1\n",
       "2356330    1\n",
       "2229084    1\n",
       "2768307    1\n",
       "2219110    1\n",
       "Name: label, Length: 2715470, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (2715470, 7)\n",
      "X_test:  (678868, 7)\n",
      "y_train:  (2715470,)\n",
      "y_test:  (678868,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious cases in y_train:  2712468\n",
      "Malicious cases in y_test:  678136\n"
     ]
    }
   ],
   "source": [
    "# how many malicious cases are in each set?\n",
    "print(\"Malicious cases in y_train: \", sum(y_train))\n",
    "print(\"Malicious cases in y_test: \", sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = svm.SVC(kernel='linear', C=1, gamma=1)\n",
    "svm_linear.fit(X_train, y_train)\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "\n",
    "svm_rbf = svm.SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "svm_sig = svm.SVC(kernel='sigmoid', C=1, gamma=1)\n",
    "svm_sig.fit(X_train, y_train)\n",
    "y_pred_sig = svm_sig.predict(X_test)\n",
    "\n",
    "svm_poly = svm.SVC(kernel='poly', C=1, gamma=1)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "y_pred_poly = svm_poly.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM F1 score:  1.0\n",
      "RBF SVM F1 score:  0.9999985264566973\n",
      "Sigmoid SVM F1 score:  0.9998667870362798\n",
      "Polynomial SVM F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Compare the accuracy of the models with F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Linear SVM F1 score: \", f1_score(y_test, y_pred_linear, average='weighted'))\n",
    "print(\"RBF SVM F1 score: \", f1_score(y_test, y_pred_rbf, average='weighted'))\n",
    "print(\"Sigmoid SVM F1 score: \", f1_score(y_test, y_pred_sig, average='weighted'))\n",
    "print(\"Polynomial SVM F1 score: \", f1_score(y_test, y_pred_poly, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the models perform almost perfectly, even now that we are using the big dataset. Using bigger datasets is usually better for the model, since it has more examples to train. However, a larger dataset can have more noise, or outliers, which can lead to overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
